1 -> dynamic
6
3
4
5
7 -> it is the same as website name
8 -> captcha (will solve it later)
9 -> captch (will solve it later) it is dynamic as well
10
11
12
13 -> captcha
14 -> beautiful soup used for html parsing
15 -> already in excel and this is not dynamic
16 it is dynamic make sure to add this in dynamic file as well also implement other button logic as well. Get to click on choose button and then do next procedure.
17 -> the one with drop down
18 -> one time
19 -> with drop down
20 -> with drop down
21 -> with drop down
22 -> with drop down
23 -> with drop down
24 -> with drop down
25 -> with drop down
26 -> paid
27 -> paid
28 -> one time
29 -> drop down
30 -> drop down
31 -> static
32 -> static
33 -> doesn't exist
34 -> static
35 -> static
36 -> drop down
37 -> static
38 -> drop down
39 -> drop down  it is in gmail.com why ...
40 -> drop down
41 -> not making any sense
42 -> drop down
43 -> static
44 -> drop down
45 -> same as 44
46 -> static
47 -> static
48 -> random
49 -> drop down
50 -> added in static
51 -> static
52 -> static
53 -> Problem Loading Page
54 -> static
55 -> already done
56 -> already done and now added to dynamic
57 -> drop down
58 -> drop down
59 -> dynamic
60 -> static
61 -> static
64 -> not working
65 -> require login
66 -> static 
67 -> no email on this page
68 -> static
69 -> static
70 -> not looking like a domain website
71 -> static
72 -> not working
73 -> not working
74 -> paid
75 -> not a disposable source
76 -> not a disposable source
77 -> not a disposable source
78 -> not responding
79 -> static
80 -> not working
81 -> static same website as 79
82 -> not working
83 -> not working
84 -> not working
85 -> static
86 -> not working
87 -> not found
88 -> paid
89 -> not working
90 -> not working
91 -> not working
92 -> not working
93 -> static
94 -> not working
95 -> not working
96 -> not working
97 -> static
98 -> not working
99 -> not working
100 -> not working
101 -> static
102 -> same as prev
103 -> not working
104 -> under construction



Ref Scrapers
Inbox scraper - getnada:  click button and then drop down form will show ->fixed drop down
Guerilla scraper: drop down appears easily -> fixed drop down
MailCatch scraper: static data, just go to that xpath and by id fetch data ->static website
TempMail scraper: Where there is dynamic data generation like copy button available and diff domains gen  -> dynamic

There are plenty of functions selenium can offer, just think how you have extract certain info and then work with selenium

Documentation for Xpath:
https://www.lambdatest.com/blog/complete-guide-for-using-xpath-in-selenium-with-examples/


Fake Mail, Minute Inbox, Ten Min Mail, Mail Catch, Temp Mail static, inbox kitten, tempail
Guerilla, Inboxes with Drop down

Make generic script for all these
Tomorrow make drop down scrapers more generic

Separate the dynamic and static scrapers

In office I will make generic scrapers and include all the scrapers that have been added so far, think if some code needs to be changed





//Now disposable provider: https://temprmail.com

source, date

What to modify now, and work on that

You've to directly update the CSV File, Add columns source and date there, fetch the source from link, and date will be current date
basically now it will be a object that will be inserted into a csv

Get anonbox and floodout in static file
Done with all of this

Now search some other domains there

Got a website info with a lot of disposable domains, let's scrape that

https://www.mailcheck.ai

Now exploring the domains from the start, have got 2 important resources as well.

Ask if these resources are valid
https://joewein.net/spam/spam-freemailer.htm
https://verifymail.io/domain/promail9.net
https://gist.github.com/mpyw/6b59ffbe517da9cccbf40db9aa30d09b
https://www.mailcheck.ai/provider/temp-mail.org


Update Drop Down logic according to your work, of updating source if exists


New Tasks

disposable source not found empty -> simply run your scrapers on this -> previously 18363 records
new disposable if source empty set database as a source -> simply run your scrapers on this first, and then use pandas to do some
data manipulation where the column will be empty enter the source as database. The merge both csvs and avoid duplicates 

new disposable file -> previously 188308

in new disposable file instead of appending the content just check whether it exist or not just fill the source, as we have to merge
both these csv's then


Now first handle that disposable-domains file, run all your scrapers on that.

Then handle 2nd file run all your scrapers just to update the source, and then do pandas data manipulation to populate the column
with source = database.

Then the last step merge both csv's, you have include unique domains, I have to decide which duplicated domain to drop, 
the duplicate coming from previous file should be dropped as the source there will be empty or not
if empty means that in new file source of database is added
if not empty no matter which to drop as you have populate the source in both 

18460 before git scraper in disposable db

Working with disposable domain file, keeping the format
Complete the new disposable file now running each scraper and then merge both csvs


email validation
whether email exist or not, this is the main part 